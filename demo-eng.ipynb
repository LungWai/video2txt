{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <h1> English version of audio to text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <h2> 1. Enviroment & dependency setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <h2> 2. function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lwsze/miniconda3/envs/text/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# function block\n",
    "import os\n",
    "import librosa\n",
    "import torch\n",
    "import numpy as np\n",
    "from docx import Document\n",
    "from transformers import pipeline \n",
    "from transformers import WhisperModel, WhisperConfig, WhisperFeatureExtractor\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "\n",
    "def convert_video_to_text(input_file, output_file, output_format, time_flag):\n",
    "    # Load the speech-to-text model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.cuda.empty_cache()\n",
    "    pipe = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-medium\", device=device)\n",
    "    # Convert video to audio\n",
    "    audio_file = convert_video_to_audio(input_file)\n",
    "    with open(output_file, \"a\") as f:\n",
    "        f.write(f\"{input_file}:\\n\")\n",
    "    for i in audio_file:\n",
    "        transcription = transcribe_audio_to_text(device, i, pipe)\n",
    "        save_transcription_to_text(i, transcription, output_file,time_flag)\n",
    "    os.system(f'rm -rf *.wav')\n",
    "    print(f\"{input_file} completed\")\n",
    "                            \n",
    "def convert_video_to_audio(input_file):\n",
    "    # Convert video to audio using ffmpeg\n",
    "    audio_file = \"temp.wav\"\n",
    "    os.system(f\"ffmpeg -i {input_file} -vn -acodec pcm_s16le -ar 16000 -ac 1 {audio_file}\")\n",
    "    \n",
    "    # Split audio into 5 minute segments\n",
    "    duration = librosa.get_duration(filename=audio_file)\n",
    "    split_files = []\n",
    "    for i in range(0, int(duration), 100):\n",
    "        split_file = f\"split_{i}.wav\"\n",
    "        os.system(f\"ffmpeg -i {audio_file} -ss {i} -t 100 {split_file}\")\n",
    "        split_files.append(split_file)\n",
    "    \n",
    "    return tuple(split_files)\n",
    "\n",
    "\n",
    "def transcribe_audio_to_text(device, audio_file, pipeline):\n",
    "    # Load audio file\n",
    "    audio_input, _ = librosa.load(audio_file, sr=16000)\n",
    "\n",
    "    # Transcribe audio to text\n",
    "    transcription = pipeline(audio_input, max_new_tokens=256, generate_kwargs={\"task\":\"translate\"},\n",
    "                        chunk_length_s=30,\n",
    "                        batch_size  = 8,\n",
    "                        )\n",
    "\n",
    "    return transcription\n",
    "\n",
    "def save_transcription_to_text(i, transcription, output_file, time_flag):\n",
    "    # Save transcription to text file\n",
    "    tmp, _ = i.split(\".\")\n",
    "    _, time = tmp.split(\"_\")\n",
    "    with open(output_file, \"a\") as file:\n",
    "        if transcription:\n",
    "            if not time_flag:\n",
    "                content = transcription[\"text\"]\n",
    "                file.write(f\"{content}\\n\")\n",
    "            else: \n",
    "                content = transcription[\"text\"]\n",
    "\n",
    "                file.write(f\"Time: {time}s  Content: {content}\\n\")\n",
    "    os.system(f'rm -rf {i}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <h2> 3. folder run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Control block for single folder\n",
    "\n",
    "# Input file folder\n",
    "input_folder = \"input\"\n",
    "\n",
    "# Output file folder\n",
    "output_folder = \"output\"\n",
    "\n",
    "# Choose output format\n",
    "output_format = \"text\" \n",
    "\n",
    "# Choose whether output timestamp\n",
    "time_flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lwsze/projects/video-2-text\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the current working directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split file completed on input\n"
     ]
    }
   ],
   "source": [
    "# split super large file\n",
    "# if time of the file > 30 min, split it inside the folder into 20 min each\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "for filename in os.listdir(input_folder):\n",
    "    in_file_path = os.path.join(input_folder, filename)\n",
    "    if os.path.isfile(in_file_path) and in_file_path.endswith(\".mp4\"):\n",
    "        if VideoFileClip(in_file_path).duration > 1200:\n",
    "            audio_file = f\"{in_file_path.strip('.mp4')}.wav\"\n",
    "            os.system(f\"ffmpeg -i {in_file_path} -vn -acodec pcm_s16le -ar 16000 -ac 1 {audio_file}\")\n",
    "            os.system(f'rm -rf {in_file_path}')\n",
    "            duration = librosa.get_duration(filename=audio_file)\n",
    "            for i in range(0, int(duration), 1200):\n",
    "                print(\"inside loop\")\n",
    "                split_file = f\"{audio_file.strip('.wav')}_split_{i}.wav\"\n",
    "                os.system(f\"ffmpeg -i {audio_file} -ss {i} -t 1200 {split_file}\")\n",
    "            os.system(f'rm -rf {audio_file}')\n",
    "clear_output()\n",
    "print(f\"Split file completed on {input_folder}\")           \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All transcription completed\n"
     ]
    }
   ],
   "source": [
    "# folder transcription\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    in_file_path = os.path.join(input_folder, filename)\n",
    "    out_file_path = os.path.join(output_folder, f\"{filename.strip('.mp4').strip('.wav')}.txt\")\n",
    "    if os.path.isfile(in_file_path):\n",
    "        print(f\"{in_file_path} is processing\")\n",
    "        convert_video_to_text(in_file_path, out_file_path, output_format, time_flag)\n",
    "\n",
    "clear_output()\n",
    "print(\"All transcription completed\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <h2> 4. Merge up file tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is optional code block for merging split file previously made\n",
    "# Not for small file < 20 min that does not require a split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "folder_path = output_folder\n",
    "\n",
    "# Acquire all files inside the folder using list comprehension\n",
    "files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, file))]\n",
    "\n",
    "# for i in files:\n",
    "#     print(i)\n",
    "# print(\"end of file dir\")\n",
    "\n",
    "\n",
    "def copy_files(file_list, output_file):\n",
    "    with open(output_file, 'w') as output:\n",
    "        for file_name in file_list:\n",
    "            with open(file_name, 'r') as file:\n",
    "                output.write(file.read())\n",
    "                output.write('\\n')  # Add a newline between file contents\n",
    "\n",
    "exp = \"(?P<name>.*?)_split_(?P<session>.*?).txt\"\n",
    "pattern = re.compile(exp)\n",
    "dict = defaultdict(list)\n",
    "\n",
    "# Print the list of files\n",
    "for file in files:\n",
    "    result = re.search(pattern, file)\n",
    "    if result:\n",
    "        dict[result.group(\"name\")].append(result.group(\"session\"))\n",
    "\n",
    "for name, session in dict.items():\n",
    "    # print(f\"{name}: {sorted(session)}\")\n",
    "    newFileName = f\"{name}_merged\"\n",
    "    originalFileName = [name+\"_split_\"+i+\".txt\" for i in sorted(session)]\n",
    "    copy_files(originalFileName,newFileName)\n",
    "    for file in originalFileName:\n",
    "        os.remove(file)\n",
    "\n",
    "print(\"Merging completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### <h2> 5. file run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using re to merge files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Control block for single file\n",
    "\n",
    "# Input file location\n",
    "input_file = \"input/input.mp4\"\n",
    "\n",
    "# Output file location\n",
    "output_file = \"output/output.txt\"\n",
    "\n",
    "# Choose output format\n",
    "output_format = \"text\" \n",
    "\n",
    "# Choose whether output timestamp\n",
    "time_flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All transcription completed\n"
     ]
    }
   ],
   "source": [
    "# single file transcription\n",
    "convert_video_to_text(input_file, output_file, output_format, time_flag)\n",
    "clear_output()\n",
    "print(\"All transcription completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### <h2> 6. Option: Remove file and resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! rm -rf *.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! rm -rf input/*.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf input/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf output/*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
